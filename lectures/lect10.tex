\section{Хештаблицы, цепочки}%
\label{sec:Хештаблицы, цепочки}

У нас есть некоторое множество, в которое мы хотим:
\begin{itemize}
    \item Добавить (ключ, значение).
    \item Удалить ключ.
    \item Получить значение по ключу.
\end{itemize}

Мы уже умеем делать это при помощи деревьев поиска за $O(log(n))$. Научимся делать это за константу. \\
Будем считать, что все ключ лежат в некотором множестве $U$.

\subsection{Прямая адресация.}%
\label{sub:Прямая адресация.}

Вспомним сортировку подсчетом, заведем таблицу размером $\lvert U \rvert$, занумеровав элементы. \\
Теперь все операции сводятся просто к работе с ячейкой массива. \\
Этот подход очевидно неидеален, ведь множество $U$ может не иметь разумного ограничения сверху. \\

\subsection{Хеш-функции}%
\label{sub:{Хеш-функции}}

Чаще всего используется некоторое подмножество $U$, мы можем использовать этот факт. \\
Введем хеш-функцию $h: U \to Z_M$. \\
Теперь будем взаимодействовать с одной из $M$ ячеек, соответствующих значениям Хеш-функции. \\
Однако и хеш-функция не лишена проблем, взять хотя бы коллизии. Для их разрешения существуют два метода: \\
 \begin{itemize}
    \item Цепочки.
    \item Открытая адресация. (Не путать с прямой).
\end{itemize}

\subsection{Метод цепочек}
Пусть у нас возникла ситуация, когда образы двух различных ключей совпадают, тогда в ячейке вместо значения, 
соответствующего ключу, будем хранить связный список пар $(key, value)$, которые в эту ячейку попали.

\paragraph{Оценим время работы}%
\label{par:Оценим время работы}
Очевидным образом добавление работает за $O(1)$, ведь это просто переход в ячейку и добавление в начало списка. \\
С удалением и добавлением сложнее, ведь они, помимо перехода, должны в худшем случае просмотреть всю цепочку, 
поэтому их можно оценить как $O(\lvert C^k \rvert)$ --- длина соответствующей цепочки.

\begin{note}
    Стоит заметить, что добавлению может потребовать пройтись по цепочке чтобы не добавлять одно и то же значение два раза,
    тогда время работы будет оцениваться как $O(1 + \lvert C^k \rvert)$
\end{note}

\subsubsection{Простое равномерное хеширование}
Simple Uniform Hashing.
На длины цепочек влияет хеш-функция, поэтому нам хотелось бы подобрать ее оптимальнее. \\
Заведем $\mathbb{H}$ --- пространство всех хеш функций вида $h: U \to Z_M$. \\ 

Каждая хеш-функция задается своими значениями на всех возможных ключах, 
то есть вектором из $\lvert U \rvert$ координат. \\

Чтобы сконструировать SUH-функцию, будем набирать этот вектор независимо по каждой координате,
каждое значение которой имеет вероятность появления $\frac{1}{M}$.

\paragraph{Мат. ожидание времени операции.}
\begin{theorem}
    В предположении Simple Uniform Hashing мат. ожидание длины цепочки --- $O(\frac{N}{M})$, где $N$ --- число добавленных ключей.
\end{theorem}

\begin{proof} \ \\
    \[
        \lvert C^j \rvert = \sum \limits_{i = 1}^{N} I(h(k_i) = j)
        \Rightarrow E \lvert C^j \rvert = \sum \limits_{i = 1}^{N} P(h(k_i) = j)
    \]
    Так как значение функции равномерно выбиралось из всего множества ключей $P(h(k_i) = j) = \frac{1}{M} \Rightarrow E\lvert C^j \rvert = \frac{N}{M}$ 
\end{proof}

\begin{Def}
    \textbf{Load factor} --- $\alpha = \frac{N}{M}$ --- показатель загруженности таблицы.
\end{Def}

\begin{corollary}
    Время работы \textit{неуспешного} поиска значения по ключу или же удаления для всех Хеш-функций имеют мат. ожидание времени работы $O(1 + \frac{N}{M})$
\end {corollary}

\begin{theorem}
    В предположении SUH среднее по всем ключам мат. ожидание \textit{успешного} поиска или удаления $O(1 + \frac{N}{M})$.
\end{theorem}

\begin{note}
    Это более сильное утверждение чем в предыдущей теореме, которая ничего не говорит о ключах. \\
    По сути, теорема говорит, что если мы выбрали случайную хеш-функцию, а за тем случайный ключ, 
    то для него все будет работать недолго.
\end{note}

\begin{proof} \ \\
    Пусть наши ключи в порядке добавления были $\{k_1, ..., k_N\}$. \\
    Тогда время поиска значения по ключу $k_i$:  $T(k_i)$ $= \lvert \{j > i: h(k_j) = h(k_i)\} \rvert$ 
    -- число добавленных после этого совпадающих ключей, ведь как мы помним, новые пары добавляются в начало цепочки. \\
    На языке индикаторов: $T(k_i) = \sum \limits _{j = i} ^ {N} I(h(k_j) = h(k_i)$.
    Тогда среднее мат. ожидание по всем ключам это $\frac{1}{N} \sum \limits _{i = 1} ^ {N} E [\sum \limits _{j = i}^{N} I_{i, j}]$ \\
    Так как $P(h(k_i) = h(k_j)) = \frac{1}{M}$, то среднее мат ожидание равняется $\frac{1}{N} \sum \limits _{i = 1} ^ {N}[1 + \frac{N - i}{M}] = O(1 + \frac{N}{M})$
\end{proof}

\paragraph{Rehash}
Однако с ростом $N$ время работы операций так же растет. Добьемся того чтобы амортизированная оценка была  $O(1)$: \\
Пусть в какой-то момент  $N$ превысила  $M$, тогда возьмем новую функцию  $h: U \to Z_{2M}$, то есть увеличим число ячеек в таблице, 
тогда старые ключи придется пересчитать. \\ 
Теперь все оценки станут амортизированными. \\

\paragraph{Затраты памяти}
Стоит учесть, что для каждого из возмножных значений ключа мы должны хранить значение хеш-функции на нем,
таким образом требуется $O(\lvert U \rvert)$ памяти. Давайте сделаем лучше, сохранив краеугольный камень --- равновероятность каждого значения. 

\subsubsection{Универсальное хеширование}
Universal Hashing \\

Зафиксируем $H$ --- семейство Хеш-функций  $h: U \to Z_M$. \\
 \begin{Def}
     \textbf{Универсальное} --- семейство хеш-функций, для которого выполняется свойство: 
      $\forall x, y \in U \hookrightarrow P_h(h(x) = h(y)) = O(\frac{1}{M})$.
\end{Def}

Нас интересует мат. ожидание длины цепочки для фиксированного ключа:
\[
    E\lvert C^k \rvert = \sum \limits _{i = 1}^{N} P(h(k_i) = h(k)) \leq 1 + O(\frac{N}{M})
.\] 
Единица появляется так как при совпадении ключей вероятность равенства хешей --- единица. \\

Построим универсальное семейство, параметризованное двумя числами: \\
Будем хешировать число: $U = \{0, ..., p - 1\}$, где  $p$ --- достаточно большое простое число. \\
\[
    h_{a, b}(x) = ((ax + b) \% p) \% m
\]

Не трудно заметить, что не имеет смысла брать $a$ и  $b$ большие чем  $p$  $Rightarrow a \in {1, ..., p - 1}, b \in {0, ..., p - 1}$. \\
\begin{prop}
   Такое семейство --- универсально.
\end{prop}

\begin{proof} \ \\
    В силу простоты $p$ $\forall x, y \hookrightarrow ax + b \equiv ay + b (\mod p) \iff x \equiv y (\mod p)$\\
    Таким образом колизия может возникнуть только после того как мы возьмем значение по модулю $m$. \\

    Проанализируем когда при взятии по модулю бывают коллизии: \\ 
    Пара $(ax + b, ay + b)$ при фиксированных  $x$ и  $y$ и варьирующихся $a$ и  $b$ пробегает все точки квадрата без диагонали.
    Даю установку, вы видите рисунок.
    Значит все точки рано или поздно будут достигнуты. \\
    При этом $P(h(x) = h(y)) = P((ax + b) \% m = (ay + b) \% m) = P(u \% m = v \% m)$

    Кроме того, $u, v \in Z_p: u \neq v$, всего таких пар $p(p - 1)$. \\
    Тогда разница между  $u$  и склеивающимися с ним значениями --- ровно $m$. \\
    Тогда склеивающиеся с $u$  можно количественно оценить сверху как $(\lceil \frac{p}{M} \rceil - 1) $. \\
    Тогда общее число склеивающихся пар оценивается как $p \cdot (\lceil \frac{p}{M} \rceil - 1)$. \\
    Значит вероятность совпадения можно оценить как $\frac{p \cdot (\lceil \frac{p}{M} \rceil - 1)}{p(p - 1)}  \leq \frac{\frac{p + M - 1}{M} - 1}{p - 1} = \frac{1}{M}$.
\end{proof}

\subsection{Задача Fixed Set, Static Perfect Hashing}
По заданному набору из $N$ ключей нам нужно построить Fixed Set --- структуру, 
позволяющую по ключу получать значение и делать это в худшем случае за $O(1)$ по времени, $O(n)$ по памяти и  $O(n)$ по времени построения.

Заведем таблицу размера $M$. \\
Выберем произвольную хеш-функцию и разложим ключи по ячейкам, руководствуясь этой функцией. \\
Пусть в $i$-той ячейке хранятся  $n_i$ значений, построим еще одну таблицу, в которой  $n_i ^ 2$ ячеек, и у которой \textit{нет коллизий},
сохраним указатель на эту новую таблицу в ячейке исходной таблицы. Таким образом получение значение по ключу будет происходить за $O(1)$, 
ведь это просто просто обращение к индексу сначала по глобальной хеш-функции, а затем по локальной. \\
Таким образом, из неравенства Маркова получаем $P($\#коллизий на $n_i$ объектов в  $n_i ^ 2$ ячейках $\geq 1) \leq \frac{1}{2}$  

Имеем вероятность того что есть коллизия не более чем $\frac{1}{2}$. \\
Тогда мы можем просто перебирать хеш-функции из семейства и достаточно рано мы получим ту, которая не дает коллизий.

Мы выполнили ограничение по времени, но возможно ситуация, когда глобальная хеш-функцию кладет все элементы в одну ячейку, тогда нарушается условие по памяти. \\
Чтобы этого избежать будем подбирать глобальную хеш-функцию так, чтобы $\sum n_i ^2$ была  $O(N)$. \\
$E \sum \lvert C^i \rvert ^2 = E \sum [\frac{\lvert C^i \rvert * \lvert C^i - 1}{2} * 2 + \lvert C^i \rvert]$ \\
Мат. ожидание суммы длин цепочек это в точности $N$, $\frac{\lvert C^i \rvert * \lvert C^i - 1}{2}$ --- количество пар в цепочке, мат. ожидание их суммы это количество коллизий, 
тогда E $\sum \lvert C^i \rvert ^2 = N + 2 * E$ \#числа коллизий $ = N + 2 \cdot \sum \limits _{i < j} P(h(k_i) == h(k_j)) = N + 2 * \frac{N(N - 1)}{2M}$. \\
В предоположении что $N = M$ получаем  $O(N)$. 
Из неравенства Маркова имеем  $P(\sum n_i ^ 2 > 4N) \leq \frac{2N}{4N} = \frac{1}{2}$.

\begin{lemma}
    Пусть $\xi_1, \xi_2, ...$ ---  независимые случайные величины, которые принимают $\{0, 1\}$ и $P(\xi_i = 0) < p \in (0, 1)$. \\
    Пусть $\eta = \min \limits _k {\xi_k = 1}$. \\
    Тогда  $E\eta \leq \frac{1}{(1 - p)^2}$
\end{lemma}

\begin{proof} \ \\
    \[
        P(\eta = \infty) = P(\xi_1 = 0) \cdot P(\xi_2 = 0) \cdot ... \leq \lim_{k \to \infty} p^k = 0
    \]
    \[
        E\eta = \sum \limits _{k = 0}^{\infty} k \cdot P(\xi_1 = \xi_2 = ... = \xi_{k - 1} = 0, \xi_k = 1) \leq \sum \limits _{k = 0}^{\infty} k \cdot p ^ {k - 1} = \frac{1}{(1 - p)^2}
    \]
\end{proof}

Тогда мы можем сделать вывод, что мат. ожидание времени перебора каждой из хеш-функций это константа. Всех этих функций $O(N)$, значит и время построение  $O(N)$. \\
Такое хеширование и называется Perfect Hashing.
